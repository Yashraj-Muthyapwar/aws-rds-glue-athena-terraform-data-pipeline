<div align="center">

# ğŸ—ï¸ Retail Analytics Platform

**Batch ETL & Real-Time ML Recommendations on AWS**

A productionâ€‘grade data pipeline that decouples analytics from OLTP, transforms raw retail data into a star schema, and delivers realâ€‘time product recommendations all provisioned with Terraform IaC.

**Tech stack:** Batch ETL (RDS â†’ Glue â†’ S3 â†’ Athena) and realâ€‘time ML recommendations (Kinesis â†’ Lambda â†’ pgvector) on AWS.


[![Terraform](https://img.shields.io/badge/IaC-Terraform-7B42BC?logo=terraform&logoColor=white)](https://www.terraform.io/)
[![AWS](https://img.shields.io/badge/Cloud-AWS-FF9900?logo=amazonaws&logoColor=white)](https://aws.amazon.com/)
[![Glue](https://img.shields.io/badge/ETL-AWS%20Glue-1A73E8?logo=amazonaws&logoColor=white)](https://aws.amazon.com/glue/)
[![Athena](https://img.shields.io/badge/Query-Amazon%20Athena-232F3E?logo=amazonaws&logoColor=white)](https://aws.amazon.com/athena/)
[![Kinesis](https://img.shields.io/badge/Streaming-Kinesis-FF4F00?logo=amazonaws&logoColor=white)](https://aws.amazon.com/kinesis/)
[![pgvector](https://img.shields.io/badge/VectorDB-pgvector-336791?logo=postgresql&logoColor=white)](https://github.com/pgvector/pgvector)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

## ğŸ’¡ Problem Statement

A retail company runs expensive analytical queries directly against its production OLTP database, causing performance degradation and scalability bottlenecks. This project solves that by implementing a fully decoupled, cloudâ€‘native analytics and recommendation platform on AWS:

1. **Batch ETL Pipeline** â€” Transforms operational data into analytics-ready formats by extracting data from **RDS MySQL**, processing it using **AWS Glue (PySpark)**, storing it in **Parquet star schema** format on **S3**, and enabling analytical queries through **Athena**.

2. **Real-Time ML Recommendations** â€” Delivers low-latency personalization by ingesting live user activity via **Kinesis Data Streams**, running embedding-based inference in **Lambda** against a **pgvector database**, and delivering recommendation outputs to **S3** via **Firehose**.

3. **Resilient Web Infrastructure** â€” Ensures production-grade availability and scalability through an **Application Load Balancer** distributing traffic across **Multi-AZ EC2 Auto Scaling instances**, with **CloudWatch** providing monitoring and operational visibility aligned with AWS Well-Architected best practices.

## ğŸ”„ End-to-End Data Flow

The three components form a single unified system: the web tier (ALB + EC2 Auto Scaling) serves the retail application and generates order and event data â†’ the batch ETL pipeline nightly extracts that data from RDS MySQL and transforms it into a star schema for analytics â†’ the streaming pipeline simultaneously processes real-time browse events through Kinesis, performs embedding-based inference against pgvector, and delivers personalized recommendations back to S3.

## ğŸ›ï¸ Architecture

**Batch ETL Pipeline:**

![Batch ETL Architecture](./images/batch-etl-architecture.png)

**ML Recommendation Pipeline (Batch + Streaming):**

![Streaming Batch Architecture](./images/streaming-batch-architecture.png)

![Streaming Real-time Architecture](./images/streaming-realtime-architecture.png)

**Web App Infrastructure:**

![Web App Architecture](./images/web-app-architecture.png)


## ğŸ› ï¸ Tech Stack

| Layer | Services |
|-------|----------|
| **Source** | Amazon RDS (MySQL) |
| **ETL** | AWS Glue (PySpark) |
| **Storage** | Amazon S3 (Parquet + Snappy) |
| **Serving** | Amazon Athena |
| **Streaming** | Kinesis Data Streams, Kinesis Firehose |
| **Compute** | AWS Lambda, EC2 Auto Scaling |
| **Vector DB** | RDS PostgreSQL + pgvector |
| **Networking** | VPC, ALB, Security Groups, Multi-AZ |
| **Monitoring** | Amazon CloudWatch |
| **IaC** | Terraform (modular HCL), AWS CloudFormation |

## ğŸ“ Project Structure

```
aws-retail-data-pipeline/
â”‚
â”œâ”€â”€ batch-etl-pipeline/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ glue.tf               # Glue job, crawler, catalog, RDS connection
â”‚   â”‚   â”œâ”€â”€ iam_roles.tf
â”‚   â”‚   â”œâ”€â”€ network.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ backend.tf
â”‚   â”‚   â””â”€â”€ assets/
â”‚   â”‚       â””â”€â”€ glue_job.py       # PySpark ETL â†’ Star Schema
â”‚   â”œâ”€â”€ scripts/setup.sh
â”‚   â”œâ”€â”€ data/mysqlsampledatabase.sql
â”‚   â””â”€â”€ dashboard.ipynb           # Athena analytics & visualizations
â”‚
â”œâ”€â”€ streaming-recommendation-pipeline/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ main.tf               # Root: etl â†’ vector_db â†’ streaming
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ backend.tf
â”‚   â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”‚   â”œâ”€â”€ etl/              # Glue ETL for ML training data
â”‚   â”‚   â”‚   â”œâ”€â”€ vector-db/        # RDS PostgreSQL + pgvector
â”‚   â”‚   â”‚   â””â”€â”€ streaming-inference/ # Kinesis + Lambda
â”‚   â”‚   â””â”€â”€ assets/
â”‚   â”‚       â”œâ”€â”€ glue_job/etl_job.py
â”‚   â”‚       â””â”€â”€ transformation_lambda/main.py
â”‚   â”œâ”€â”€ scripts/setup.sh
â”‚   â””â”€â”€ sql/embeddings.sql        # pgvector setup & S3 import
â”‚
â”œâ”€â”€ app-infrastructure/
â”‚   â”œâ”€â”€ template.yaml             # CloudFormation: ALB + EC2 Auto Scaling + CloudWatch
â”‚   â”œâ”€â”€ template.json             # same stack in JSON format
â”‚
â””â”€â”€ images/                       # Architecture diagrams
```

## ğŸš€ Getting Started

### Prerequisites

- **Terraform** â‰¥ 1.0
- **AWS CLI** v2 (configured with appropriate IAM permissions)
- **MySQL** & **psql** clients
- **Python** 3.8+

### 1. Deploy the App Infrastructure

```bash
aws cloudformation deploy \
  --template-file app-infrastructure/template.yaml \
  --stack-name retail-app-infra \
  --capabilities CAPABILITY_IAM
```

### 2. Deploy the Batch ETL Pipeline

```bash
# Set environment variables
export DB_USERNAME=your_username
export DB_PASSWORD=your_password

source batch-etl-pipeline/scripts/setup.sh
cd batch-etl-pipeline/terraform
terraform init && terraform plan && terraform apply

# Trigger the ETL job
aws glue start-job-run --job-name <project>-etl-job | jq -r '.JobRunId'
```

### 3. Deploy the Streaming Recommendation Pipeline

```bash
export DB_USERNAME=your_username
export DB_PASSWORD=your_password

source streaming-recommendation-pipeline/scripts/setup.sh
cd streaming-recommendation-pipeline/terraform

# Modules deploy sequentially via depends_on: etl â†’ vector_db â†’ streaming_inference
terraform init && terraform apply

# Load embeddings into pgvector
psql --host=<VectorDBHost> --username=postgres --port=5432
\i '../sql/embeddings.sql'
```

## ğŸ“Š Data Model

Transforms 8 normalized OLTP tables into an analytics-ready **star schema**:

![Star Schema](./images/star-schema.png)

| Table | Type | Key Columns |
|-------|------|-------------|
| `fact_orders` | Fact | orderNumber, customerNumber, productCode, quantityOrdered, priceEach, orderAmount, orderDate |
| `dim_customers` | Dimension | customerNumber, customerName, contactName, creditLimit |
| `dim_products` | Dimension | productCode, productName, productLine, productVendor |
| `dim_locations` | Dimension | postalCode, city, state, country |

## ğŸ”‘ Key Design Decisions

- **Modular Terraform** â€” Three composable modules (`etl`, `vector-db`, `streaming-inference`) with explicit `depends_on` ordering for safe sequential deployment
- **Parquet + Snappy** â€” Columnar storage with compression for cost-efficient Athena queries (pay-per-query)
- **pgvector over managed Vector DB** â€” Cost-effective embedding similarity search on RDS PostgreSQL without the overhead of a dedicated vector store
- **Serverless streaming** â€” Lambda + Firehose auto-scales with traffic; zero idle cost
- **Security-first** â€” Credentials injected via environment variables, ALB security groups restrict inbound traffic, VPC isolation for all data resources
- **Validated under load** â€” Apache Benchmark stress test (1M requests, 200 concurrent connections) confirmed CloudWatch-triggered Auto Scaling fires correctly and scales back in after load drops

## ğŸ“ License
This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for more details.

## ğŸŒŸ About Me

Hi there! I'm **Yashraj Muthyapwar**, a Data Engineer passionate about building scalable, cloud-native data systems on AWS. This project reflects my hands-on experience designing real-world batch and streaming pipelines using modern data engineering tools and Infrastructure as Code.

> ### ğŸŒŸ Contributions Welcome  
> Built with â¤ï¸ on AWS to make retail analytics & realâ€‘time recommendations feel effortless.


